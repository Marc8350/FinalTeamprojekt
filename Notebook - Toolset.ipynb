{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teilautomatisierter Prozess zur Erfassung von Sicherheitswissen in einer Ontologie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der hier beschriebene Prozess ist dabei auf das Grundschutzkompendium bezogen, kann aber für andere Quellen in abgewandelter Form genauso verwendet werden. Damit der Wissensgraph immer auf dem neusten Stand ist, müssen die Bausteine im GC Storage Bucket jedes Jahr nach Erscheinen einer neuen Version des Grundschutzkompendiums aktualisiert werden und der Prozess wie folgt wiederholt werden. \n",
    "\n",
    "_Hilfsfunktionen_ werden in dem Prozess der in der Aufgabenstellung verlangt wurde nicht verwendet, dienen aber aus unserer Perspektive dazu das Tool als Baukasten für Entwickler einfacher nutzbar zu machen. \n",
    "\n",
    "Als Hilfestellung um weiter Funktionen zu entwerfen dient die [Dokumentation von owl-ready-2](https://owlready2.readthedocs.io/en/latest/)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " ### Zur Vorbereitung werden folgende Schritte benötigt:\n",
    " - Google Cloud Developer Account erstellen und lokal anmelden dabei den Schritten unter https://cloud.google.com/vertex-ai/docs/start/cloud-environment folgen\n",
    " - Vertex API und Umgebung einrichten und ein Projekt anlegen: https://cloud.google.com/vertex-ai/docs/start/cloud-environment \n",
    " - Erstellung eines Google Cloud Storage Buckets nach: https://cloud.google.com/storage/docs/creating-buckets?hl=de\n",
    " - Entwicklungsumgebung in Python \n",
    " - Installation der requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Der Prozess\n",
    "1. Herunterladen der Kreuzreferenztabelle, den Bausteinen in einzelnen PDFs und des Grundschutzkompendiums in Buchformat\n",
    "2. Hochladen der Bausteine in den Google Cloud Storage Bucket. \n",
    "3. Liste der Dokumente laden über die Google Cloud shell per : gsutil ls gs://DEIN_BUCKET/ und in ein Textdokument abspeichern\n",
    "4. Überprüfen ob die hier gelisteten Gefahren noch den im Grundschutzkompendium geführten Gefahren entsprechen"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T11:36:36.866503Z",
     "start_time": "2024-08-06T11:36:36.854522Z"
    }
   },
   "source": "gefahren = [{'handle': 'G 0.1', 'text': 'Feuer'}, {'handle': 'G 0.2', 'text': 'Ungünstige klimatische Bedingungen'}, {'handle': 'G 0.3', 'text': 'Wasser'}, {'handle': 'G 0.4', 'text': 'Verschmutzung, Staub, Korrosion'}, {'handle': 'G 0.5', 'text': 'Naturkatastrophen'}, {'handle': 'G 0.6', 'text': 'Katastrophen im Umfeld'}, {'handle': 'G 0.7', 'text': 'Großereignisse im Umfeld'}, {'handle': 'G 0.8', 'text': 'Ausfall oder Störung der Stromversorgung'}, {'handle': 'G 0.9', 'text': 'Ausfall oder Störung von Kommunikationsnetzen'}, {'handle': 'G 0.10', 'text': 'Ausfall oder Störung von Versorgungsnetzen'}, {'handle': 'G 0.11', 'text': 'Ausfall oder Störung von Dienstleistungsunternehmen'}, {'handle': 'G 0.12', 'text': 'Elektromagnetische Störstrahlung'}, {'handle': 'G 0.13', 'text': 'Abfangen kompromittierender Strahlung'}, {'handle': 'G 0.14', 'text': 'Ausspähen von Informationen (Spionage)'}, {'handle': 'G 0.15', 'text': 'Abhören'}, {'handle': 'G 0.16', 'text': 'Diebstahl von Geräten, Datenträgern oder Dokumenten'}, {'handle': 'G 0.17', 'text': 'Verlust von Geräten, Datenträgern oder Dokumenten'}, {'handle': 'G 0.18', 'text': 'Fehlplanung oder fehlende Anpassung'}, {'handle': 'G 0.19', 'text': 'Offenlegung schützenswerter Informationen'}, {'handle': 'G 0.20', 'text': 'Informationen oder Produkte aus unzuverlässiger Quelle'}, {'handle': 'G 0.21', 'text': 'Manipulation von Hard- oder Software'}, {'handle': 'G 0.22', 'text': 'Manipulation von Informationen'}, {'handle': 'G 0.23', 'text': 'Unbefugtes Eindringen in IT-Systeme'}, {'handle': 'G 0.24', 'text': 'Zerstörung von Geräten oder Datenträgern'}, {'handle': 'G 0.25', 'text': 'Ausfall von Geräten oder Systemen'}, {'handle': 'G 0.26', 'text': 'Fehlfunktion von Geräten oder Systemen'}, {'handle': 'G 0.27', 'text': 'Ressourcenmangel'}, {'handle': 'G 0.28', 'text': 'Software-Schwachstellen oder -Fehler'}, {'handle': 'G 0.29', 'text': 'Verstoß gegen Gesetze oder Regelungen'}, {'handle': 'G 0.30', 'text': 'Unberechtigte Nutzung oder Administration von Geräten und Systemen'}, {'handle': 'G 0.31', 'text': 'Fehlerhafte Nutzung oder Administration von Geräten und Systemen'}, {'handle': 'G 0.32', 'text': 'Missbrauch von Berechtigungen'}, {'handle': 'G 0.33', 'text': 'Personalausfall'}, {'handle': 'G 0.34', 'text': 'Anschlag'}, {'handle': 'G 0.35', 'text': 'Nötigung, Erpressung oder Korruption'}, {'handle': 'G 0.36', 'text': 'Identitätsdiebstahl'}, {'handle': 'G 0.37', 'text': 'Abstreiten von Handlungen'}, {'handle': 'G 0.38', 'text': 'Missbrauch personenbezogener Daten'}, {'handle': 'G 0.39', 'text': 'Schadprogramme'}, {'handle': 'G 0.40', 'text': 'Verhinderung von Diensten (Denial of Service)'}, {'handle': 'G 0.41', 'text': 'Sabotage'}, {'handle': 'G 0.42', 'text': 'Social Engineering'}, {'handle': 'G 0.43', 'text': 'Einspielen von Nachrichten'}, {'handle': 'G 0.44', 'text': 'Unbefugtes Eindringen in Räumlichkeiten'}, {'handle': 'G 0.45', 'text': 'Datenverlust'}, {'handle': 'G 0.46', 'text': 'Integritätsverlust schützenswerter Informationen'}, {'handle': 'G 0.47', 'text': 'Schädliche Seiteneffekte IT-gestützter Angriffe'}]",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laden benötigter Importe "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import base64, json\n",
    "import pandas as pd\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
    "import vertexai.preview.generative_models as generative_models\n",
    "import os \n",
    "import fileinput\n",
    "import re\n",
    "from owlready2 import *\n",
    "import logging\n",
    "from rapidfuzz import fuzz\n",
    "import locale"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T11:36:40.187048Z",
     "start_time": "2024-08-06T11:36:40.180137Z"
    }
   },
   "cell_type": "code",
   "source": "locale.setlocale(locale.LC_ALL, 'de_DE')",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'de_DE'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier bitte alle persönlichen benötigten Variablen abspeichern: \n",
    "- Vertex project id\n",
    "- Pfad zur Kreuzreferenztabelle \n",
    "- Pfad zur Liste mit den Links zu den Bausteinen im Google Cloud Bucket. \n",
    "- Link zum Storage Bucket für zwischenergebnisse.\n",
    "Damit unterschiedliche Versuche nicht überlappen und zum Zweck der Versionierung, sollte auch bei jedem Durchlauf ein resultname (Name der Outputdatei OHNE Endung) nach einem Versionierungsschema gewählt werden."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T11:36:40.190400Z",
     "start_time": "2024-08-06T11:36:40.188089Z"
    }
   },
   "source": [
    "projectid = \"gen-lang-client-0489091220\"\n",
    "path_to_excel_file = r'krt2023_Excel.xlsx'\n",
    "file_path = \"example copy.txt\"\n",
    "storage_bucket = \"gs://bausteinebsi/\"\n",
    "resultname = \"cybersecurity_complete_v14\"\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "In der Funktion **generate()** wird das Dictionary, das die Inhalte aus dem Grundschutzkompendium enthält, durch Gemini erstellt. Das Modell wird zuerst konfiguriert und anschließend werden die Prompts gespeichert. Da es zu Problemen durch Rezitation oder als gefährlich eingestufte Inhalte kommen kann, gibt es zwei Versionen der Prompts: eine Version, die die Beschreibungen enthält und im ersten Durchlauf des Prozesses abgerufen wird, und eine Version ohne diese Beschreibungen. Die Struktur des Dictionaries wird in den Prompts definiert; durch Anpassung dieser Prompts ist es auch möglich, andere Quellen einzulesen. Die Antworten der API werden anschließend aufbereitet."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T11:36:40.202759Z",
     "start_time": "2024-08-06T11:36:40.192338Z"
    }
   },
   "source": [
    "def generate(path, failed=False):\n",
    "        vertexai.init(project = projectid, location=\"northamerica-northeast1\")\n",
    "\n",
    "        model = GenerativeModel(\n",
    "            \"gemini-1.5-flash-001\",\n",
    "        )\n",
    "        if not failed:\n",
    "          prompt_extract1 = \"\"\"You are an ontology assistant tasked with extracting core information from a single chapter of a German cybersecurity recommendation book. Your focus is on accurately identifying and establishing the relationships between elements.\n",
    "\n",
    "                            **Extremely Important:**  \n",
    "\n",
    "                            * **For fields with specific allowed values, ensure you ONLY use those values. Do not invent or guess values.**\n",
    "                            * **The JSON output must be valid and ready for parsing. Do not include any extra formatting or explanations.**\n",
    "\n",
    "                            **The Source Material:**\n",
    "\n",
    "                            * You will be provided with a single chapter, which should be treated as one \"Asset\" in the JSON.\n",
    "\n",
    "                            **Extraction Rules:**\n",
    "\n",
    "                            1. **Identify Asset:**\n",
    "                              - The chapter's main heading is the name of the Asset.\n",
    "                              - The Asset \"handle\" is the first part of the subheading (e.g., \"SYS.1.6\").\n",
    "                              - The Asset \"text\" is a summary of the description of the asset, found in the paragraph under the \"Beschreibung\" heading. \n",
    "\n",
    "                            2. **Identify Vulnerabilities:**\n",
    "                              - Locate subheadings directly under the section titled \"Gefährdungslage.\" These are the Vulnerabilities. \n",
    "                              - The Vulnerability \"handle\" is the first part of the subheading.\n",
    "                              - The Vulnerability \"name\" is the remaining text of the subheading.\n",
    "                              - The Vulnerability \"text\" is a summary of the text below the subheading describing the vulnerability.\n",
    "\n",
    "                            3. **Identify Example Threats (For Each Vulnerability):**\n",
    "                              - Within each Vulnerability section, find paragraphs that describe Threats exploiting that Vulnerability.\n",
    "                              - The \"text\" is a summary of the text describing the example threat.\n",
    "                              - **Optional Information (If Present in the Text):**\n",
    "                                - **Threat Origin:** \"human\" or \"natural\". \n",
    "                                - **Threat Source:** \"deliberate\" or \"accidental\". \n",
    "\n",
    "                            **Output JSON Structure:**\n",
    "\n",
    "                            ```json\n",
    "                            {\n",
    "                              \"Informationsource\": \"BSI GSK 2023\",\n",
    "                              \"name\": \"[Asset Name]\",\n",
    "                              \"handle\": \"[Asset Handle]\",\n",
    "                              \"text\": \"[Asset Description]\",\n",
    "                              \"vulnerableTo\": [\n",
    "                                {\n",
    "                                  \"type\": \"specific\",\n",
    "                                  \"Informationsource\": \"BSI GSK 2023\",\n",
    "                                  \"name\": \"[Vulnerability Name]\",\n",
    "                                  \"handle\": \"[Vulnerability Handle]\",\n",
    "                                  \"text\": \"[Vulnerability Description]\",\n",
    "                                  \"exploitedBy_examples\": [\n",
    "                                    {\n",
    "                                      \"Informationsource\": \"BSI GSK 2023\",\n",
    "                                      \"name\": \"[Threat Name]\", \n",
    "                                      \"type\": \"Threat\",\n",
    "                                      \"text\": \"[Threat Description]\",\n",
    "                                      \"hasOrigin\": [\n",
    "                                        \"[ThreatOrigin]\", \n",
    "                                        ...\n",
    "                                      ], // Optional: \"human\", \"natural\", or both\n",
    "                                      \"hasSource\": [\n",
    "                                        \"[ThreatSource]\",\n",
    "                                        ...\n",
    "                                      ] // Optional: \"deliberate\", \"accidental\", or both\n",
    "                                    },\n",
    "                                    ... \n",
    "                                  ],\n",
    "                                  \"mitigatedBy\": [ \n",
    "                                    \"[Control Handle 1]\",\n",
    "                                    \"[Control Handle 2]\",\n",
    "                                    ... \n",
    "                                  ] \n",
    "                                },\n",
    "                                // ... More Vulnerabilities ...\n",
    "                              ]\n",
    "                            }\n",
    "                                \"\"\"\n",
    "        \n",
    "          prompt_extract2 = \"\"\"\n",
    "              You are an ontology assistant tasked with extracting control information from a single chapter of a German cybersecurity recommendation book. Your focus is on accurately identifying and establishing the relationships between elements.\n",
    "\n",
    "                **Extremely Important:**  \n",
    "\n",
    "                * **For fields with specific allowed values, ensure you ONLY use those values. Do not invent or guess values.**\n",
    "                * **The JSON output must be valid and ready for parsing. Do not include any extra formatting or explanations.**\n",
    "\n",
    "                **The Source Material:**\n",
    "\n",
    "                * You will be provided with a single chapter, which should be treated as one \"Asset\" in the JSON. \n",
    "\n",
    "                **Extraction Rules:**\n",
    "\n",
    "                1. **Identify Controls (For Each Vulnerability):**\n",
    "                  - Within each Vulnerability section, extract subheadings from these sections to identify relevant Controls:\n",
    "                    - \"Basis Anforderungen\" (Low-Level Controls)\n",
    "                    - \"Standard Anforderungen\" (Medium-Level Controls)\n",
    "                    - \"Anforderungen bei erhöhtem Schutzbedarf\" (High-Level Controls)\n",
    "                  - **Important:** Skip subheadings that contain the word \"entfallen.\"\n",
    "                  - The Control \"handle\" is the first part of the subheading (e.g., \"SYS.1.6.A2\").\n",
    "                  - The Control \"name\" is the remaining text of the subheading.\n",
    "                  - The Control \"text\" is the description of the control.\n",
    "                  - The Control \"isresponsible\" is the responsible entity for the control, Optional: if mentioned it can be found in [] in the control heading.\n",
    "\n",
    "                **Output JSON Structure:**\n",
    "\n",
    "                ```json\n",
    "                {\n",
    "                  \"Controls\": [ \n",
    "                    {\n",
    "                      \"Informationsource\": \"BSI GSK 2023\",\n",
    "                      \"name\": \"[Control Name 1]\",\n",
    "                      \"handle\": \"[Control Handle 1]\",\n",
    "                      \"level\": \"[Low | Medium | High]\",\n",
    "                      \"affects\": [], // Optional: \"Availability\", \"Confidentiality\", and/or \"Integrity\" ,\n",
    "                      \"text\": \"[Control Description]\", \n",
    "                      \"isresponsible\": \"[Control Responsible Entity]\" \n",
    "\n",
    "                    },\n",
    "                    // ... More Controls ...\n",
    "                  ]\n",
    "                }\n",
    "                ```\n",
    "\n",
    "                **Provide the JSON output directly. Do not include any additional text or explanations.** \n",
    "        \"\"\"\n",
    "        else: \n",
    "          prompt_extract1 = \"\"\"You are an ontology assistant tasked with extracting core information from a single chapter of a German cybersecurity recommendation book. Your focus is on accurately identifying and establishing the relationships between elements.\n",
    "\n",
    "                            **Extremely Important:**  \n",
    "\n",
    "                            * **For fields with specific allowed values, ensure you ONLY use those values. Do not invent or guess values.**\n",
    "                            * **The JSON output must be valid and ready for parsing. Do not include any extra formatting or explanations.**\n",
    "\n",
    "                            **The Source Material:**\n",
    "\n",
    "                            * You will be provided with a single chapter, which should be treated as one \"Asset\" in the JSON.\n",
    "\n",
    "                            **Extraction Rules:**\n",
    "\n",
    "                            1. **Identify Asset:**\n",
    "                              - The chapter's main heading is the name of the Asset.\n",
    "                              - The Asset \"handle\" is the first part of the subheading (e.g., \"SYS.1.6\").\n",
    "\n",
    "                            2. **Identify Vulnerabilities:**\n",
    "                              - Locate subheadings directly under the section titled \"Gefährdungslage.\" These are the Vulnerabilities. \n",
    "                              - The Vulnerability \"handle\" is the first part of the subheading.\n",
    "                              - The Vulnerability \"name\" is the remaining text of the subheading.\n",
    "\n",
    "                            3. **Identify Example Threats (For Each Vulnerability):**\n",
    "                              - Within each Vulnerability section, find paragraphs that describe Threats exploiting that Vulnerability.\n",
    "                              - **Optional Information (If Present in the Text):**\n",
    "                                - **Threat Origin:** \"human\" or \"natural\". \n",
    "                                - **Threat Source:** \"deliberate\" or \"accidental\". \n",
    "\n",
    "                            **Output JSON Structure:**\n",
    "\n",
    "                            ```json\n",
    "                            {\n",
    "                              \"Informationsource\": \"BSI GSK 2023\",\n",
    "                              \"name\": \"[Asset Name]\",\n",
    "                              \"handle\": \"[Asset Handle]\",\n",
    "                              \"vulnerableTo\": [\n",
    "                                {\n",
    "                                  \"type\": \"specific\",\n",
    "                                  \"Informationsource\": \"BSI GSK 2023\",\n",
    "                                  \"name\": \"[Vulnerability Name]\",\n",
    "                                  \"handle\": \"[Vulnerability Handle]\",\n",
    "                                  \"exploitedBy_examples\": [\n",
    "                                    {\n",
    "                                      \"Informationsource\": \"BSI GSK 2023\",\n",
    "                                      \"name\": \"[Threat Name]\", \n",
    "                                      \"type\": \"Threat\",\n",
    "                                      \"hasOrigin\": [\n",
    "                                        \"[ThreatOrigin]\", \n",
    "                                        ...\n",
    "                                      ], // Optional: \"human\", \"natural\", or both\n",
    "                                      \"hasSource\": [\n",
    "                                        \"[ThreatSource]\",\n",
    "                                        ...\n",
    "                                      ] // Optional: \"deliberate\", \"accidental\", or both\n",
    "                                    },\n",
    "                                    ... \n",
    "                                  ],\n",
    "                                  \"mitigatedBy\": [ \n",
    "                                    \"[Control Handle 1]\",\n",
    "                                    \"[Control Handle 2]\",\n",
    "                                    ... \n",
    "                                  ] \n",
    "                                },\n",
    "                                // ... More Vulnerabilities ...\n",
    "                              ]\n",
    "                            }\n",
    "                                \"\"\"\n",
    "        \n",
    "          prompt_extract2 = \"\"\"\n",
    "              You are an ontology assistant tasked with extracting control information from a single chapter of a German cybersecurity recommendation book. Your focus is on accurately identifying and establishing the relationships between elements.\n",
    "\n",
    "                **Extremely Important:**  \n",
    "\n",
    "                * **For fields with specific allowed values, ensure you ONLY use those values. Do not invent or guess values.**\n",
    "                * **The JSON output must be valid and ready for parsing. Do not include any extra formatting or explanations.**\n",
    "\n",
    "                **The Source Material:**\n",
    "\n",
    "                * You will be provided with a single chapter, which should be treated as one \"Asset\" in the JSON. \n",
    "\n",
    "                **Extraction Rules:**\n",
    "\n",
    "                1. **Identify Controls (For Each Vulnerability):**\n",
    "                  - Within each Vulnerability section, extract subheadings from these sections to identify relevant Controls:\n",
    "                    - \"Basis Anforderungen\" (Low-Level Controls)\n",
    "                    - \"Standard Anforderungen\" (Medium-Level Controls)\n",
    "                    - \"Anforderungen bei erhöhtem Schutzbedarf\" (High-Level Controls)\n",
    "                  - **Important:** Skip subheadings that contain the word \"entfallen.\"\n",
    "                  - The Control \"handle\" is the first part of the subheading (e.g., \"SYS.1.6.A2\").\n",
    "                  - The Control \"name\" is the remaining text of the subheading.\n",
    "                  - The Control \"isresponsible\" is the responsible entity for the control, Optional: if mentioned it can be found in [] in the control heading.\n",
    "\n",
    "                **Output JSON Structure:**\n",
    "\n",
    "                ```json\n",
    "                {\n",
    "                  \"Controls\": [ \n",
    "                    {\n",
    "                      \"Informationsource\": \"BSI GSK 2023\",\n",
    "                      \"name\": \"[Control Name 1]\",\n",
    "                      \"handle\": \"[Control Handle 1]\",\n",
    "                      \"level\": \"[Low | Medium | High]\",\n",
    "                      \"affects\": [], // Optional: \"Availability\", \"Confidentiality\", and/or \"Integrity\",\n",
    "                      \"isresponsible\": \"[Control Responsible Entity]\" \n",
    "                    },\n",
    "                    // ... More Controls ...\n",
    "                  ]\n",
    "                }\n",
    "                ```\n",
    "\n",
    "                **Provide the JSON output directly. Do not include any additional text or explanations.** \n",
    "        \"\"\"      \n",
    "        document1 = Part.from_uri(\n",
    "        mime_type=\"application/pdf\",\n",
    "        uri=path)\n",
    "    \n",
    "\n",
    "        generation_config = {\n",
    "            \"top_p\": 0.95,\n",
    "            \"temperature\": 0.1\n",
    "        }\n",
    "\n",
    "        safety_settings = {\n",
    "            generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "            generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "            generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "            generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        }\n",
    "        \n",
    "        response1 = model.generate_content(\n",
    "            [document1, prompt_extract1],\n",
    "            generation_config=generation_config,\n",
    "            safety_settings=safety_settings,\n",
    "            #stream=True,\n",
    "        )\n",
    "        response1_txt = response1.text.replace(\"`json\", \"\").replace(\"`\", \"\").replace(\"Ä\", \"Ae\").replace(\"Ö\", \"Oe\").replace(\"Ü\", \"Ue\").replace(\"ß\", \"ss\").replace(\"ä\", \"ae\").replace(\"ö\", \"oe\").replace(\"ü\", \"ue\")\n",
    "        response2 = model.generate_content(\n",
    "            [document1, prompt_extract2],\n",
    "            generation_config=generation_config,\n",
    "            safety_settings=safety_settings,\n",
    "            #stream=True,\n",
    "        )\n",
    "\n",
    "        response2_txt = response2.text.replace(\"`json\", \"\").replace(\"`\", \"\").replace(\"Ä\", \"Ae\").replace(\"Ö\", \"Oe\").replace(\"Ü\", \"Ue\").replace(\"ß\", \"ss\").replace(\"ä\", \"ae\").replace(\"ö\", \"oe\").replace(\"ü\", \"ue\")\n",
    "        \n",
    "        return [response1.usage_metadata, response1_txt, response2.usage_metadata, response2_txt]"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Die Funktion **llm_output_to_json()** bereitet den Output der generate()-Funktion auf, kodiert und dekodiert ihn und speichert das Ergebnis im neu erstellten Ordner working_files ab. Dadurch kann bei Fehlern in den nächsten Prozessschritten auf diese Dateien zurückgegriffen werden, wodurch der rechenaufwändige Schritt der Neuerstellung vermieden wird."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T11:36:40.209196Z",
     "start_time": "2024-08-06T11:36:40.204362Z"
    }
   },
   "source": [
    "def llm_output_to_json(output_data):\n",
    "    output_json = json.loads(output_data[1])\n",
    "    output_json.update(json.loads(output_data[3]))\n",
    "    working_dir = os.getcwd()  # Get current working directory\n",
    "    output_folder = os.path.join(working_dir, \"working_files\")\n",
    "    os.makedirs(output_folder, exist_ok=True) \n",
    "    output_file = os.path.join(output_folder, f\"{output_json['name']}.json\")  # Assuming \"name\" is in the JSON\n",
    "    # Save the JSON file\n",
    "    with open(output_file, \"w\", encoding='utf-8') as output_file:\n",
    "        output_file.write(output_data[1].join(output_data[3]))\n",
    "        print(f\"Txt file saved: {output_file}\")\n",
    "    return output_json\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**read_excel_sheet()** gibt das entsprechende Blatt zum angefragten Baustein aus der Kreuzreferenztabelle als Dataframe zurück"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T11:36:40.213536Z",
     "start_time": "2024-08-06T11:36:40.210712Z"
    }
   },
   "source": [
    "def read_excel_sheet(sheet_name, file_path = path_to_excel_file):\n",
    "  sheet_name = \"KRT_\" + sheet_name + \".xlsx\"  # Remove any spaces from the sheet name\n",
    "  df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "  return df"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**populate_json_with_excel_data()** liest die Kreuzrefferenztabelle eines Bausteinsaus und fügt die Ergebnisse dem Dictionary des entsprechenden Bausteins hinzu, die Ergebnisse überschreiben die zugehörige JSON Datei in working_files als Zwischenspeicher"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T11:36:40.219564Z",
     "start_time": "2024-08-06T11:36:40.214325Z"
    }
   },
   "source": [
    "def populate_json_with_excel_data(json_data, dataframe):\n",
    "    for control in json_data[\"Controls\"]:\n",
    "        control[\"affects\"] = []  # \n",
    "        control_handle = control[\"handle\"]\n",
    "        row = dataframe.loc[dataframe[json_data[\"handle\"]] == control_handle]\n",
    "        row_cia_value = row[\"CIA\"].tolist()[0] if len(row[\"CIA\"].tolist()) > 0 else []  # Get the \"CIA\" value from the row\n",
    "        x_indices = []\n",
    "        count = 0\n",
    "        try:\n",
    "            for value in row.values[0]:\n",
    "                if value == \"X\":\n",
    "                    x_indices.append(count)\n",
    "                count += 1\n",
    "            Gefahren = [dataframe.iloc[:, index].name for index in x_indices]\n",
    "            control[\"mitigates\"] = Gefahren\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Appending Gefahren failed due to {e}\")\n",
    "        if type(row_cia_value) == str:\n",
    "            control[\"affects\"] = row_cia_value.split() if len(row_cia_value) > 0 else []\n",
    "        \n",
    "\n",
    "    \n",
    "    #correct for mitigatedBy until now\n",
    "    for vulnerability in json_data[\"vulnerableTo\"]:\n",
    "        vulnerability[\"mitigatedBy\"] = []\n",
    "\n",
    "    working_dir = os.getcwd()  # Get current working directory\n",
    "    output_folder = os.path.join(working_dir, \"working_files\")\n",
    "    os.makedirs(output_folder, exist_ok=True) \n",
    "\n",
    "    # Construct the JSON file path within the \"working_files\" folder\n",
    "    output_file = os.path.join(output_folder, f\"{json_data['name']}.json\")  # Assuming \"name\" is in the JSON\n",
    "    # Save the JSON file\n",
    "    with open(output_file, \"w\", encoding='utf-8') as outfile:\n",
    "        json.dump(json_data, outfile, indent=4, ensure_ascii=False)  # Use indent for pretty formatting\n",
    "    return json_data"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**read_links_to_array()** liest die Links aus dem Bucket ein und stellt sie für nachfolgende Funktionen zur Verfügung. Bitte Überprüfe ob deine Links um Output der nachfolgenden Zelle angezeigt werden."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def read_links_to_array(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        links = file.read().splitlines()  # Read lines, remove newline characters\n",
    "    return links\n",
    "\n",
    "# Example usage:\n",
    "links_array = read_links_to_array(file_path)\n",
    "print(links_array)  # Output: ['https://example.com/1', 'https://example.com/2', 'https://example.com/3']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "_Hilfsfunktion_ **load_json_files()** Wird dazu verwendet um die Zwischenergebnisse aus \"working_files\" falls benötigt zu laden."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T11:36:40.228373Z",
     "start_time": "2024-08-06T11:36:40.225671Z"
    }
   },
   "source": [
    "def load_json_files(file_paths):\n",
    "    json_data = {}\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path) as file:\n",
    "            json_variable = json.load(file)\n",
    "            filename = os.path.basename(file_path).replace(\".json\", \"\")  # Get filename without the path\n",
    "            json_data[filename] = json_variable\n",
    "    return json_data"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "_Hilfsfunktion_ **modify_filename()** ist eine Hilfsfunktion die benötigt wird um die entsprechenden Datein aus dem Zwischenspeicher auf zu rufen. "
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T11:36:40.233368Z",
     "start_time": "2024-08-06T11:36:40.230562Z"
    }
   },
   "source": [
    "def modify_filename(filename):\n",
    "    # Remove \"_Edition_2023.pdf\" suffix\n",
    "    filename = filename.replace(\"_Edition_2023.pdf\", \"\").replace(storage_bucket, \"\")  # Remove suffix\n",
    "\n",
    "    # Split remaining string by underscores\n",
    "    parts = filename.split(\"_\")  \n",
    "\n",
    "    # Join first two parts with a dot\n",
    "    modified_filename = parts[0] + \".\" + parts[1]  # Join first two with '.'\n",
    "\n",
    "    # Process remaining parts based on their type\n",
    "    for part in parts[2:]:\n",
    "        if part.isdigit():  # If part is a number, join with a dot\n",
    "            modified_filename += \".\" + part\n",
    "        else:  # If part is not a number (assumed to be a word), join with a space\n",
    "            modified_filename += \" \" + part\n",
    "\n",
    "    return modified_filename\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "_Hilfsfunktion_ **load_json_from_link()** sucht aus zu einem gegebenen Link mit Hilfe der Funktionen *load_json_files* und *modify_filename* die Zwischenergebnisse zu Links und gibt deren Dictionaries zurück, um auf diese im Fall von Komplikationen zugreifen zu können."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T11:36:40.238349Z",
     "start_time": "2024-08-06T11:36:40.234124Z"
    }
   },
   "source": [
    "def load_json_from_link(link):\n",
    "    try: \n",
    "        link_text = modify_filename(link)\n",
    "        link_text = \" \".join(link_text.split(\" \")[1:]).lower()\n",
    "        subdirectory = 'working_files'  \n",
    "        file_paths = [os.path.join(subdirectory, f) for f in os.listdir(subdirectory) if f.endswith('.json')]\n",
    "        json_data = load_json_files(file_paths)\n",
    "        json_data_keys = list(json_data.keys())\n",
    "        threshold=70\n",
    "        best_match_key = None\n",
    "        best_match_ratio = 0\n",
    "        for key in json_data_keys:\n",
    "            normalized_key = key.lower().replace(\"-\", \" \")\n",
    "            ratio = fuzz.partial_ratio(link_text, normalized_key)\n",
    "            if ratio >= threshold and ratio > best_match_ratio:\n",
    "                best_match_key = key\n",
    "                best_match_ratio = ratio\n",
    "\n",
    "        if best_match_key is not None:\n",
    "            return json_data[best_match_key]\n",
    "        else:\n",
    "            logging.error(f\"Error loading JSON from link: No match found for link: {link}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading JSON from link: {e}\")\n",
    "        return None\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **intiiere_Ontologie()** - Initialisiert die Klassen, Eigenschaften und Annotationen der Ontologie.\n",
    "* **create_baustein()** - Erweitert die Ontologie mit den vorbereiteten Informationen aus einem JSON-Objekt. Zuerst werden die notwendigen Dictionary-Dateien erstellt, falls diese noch nicht existieren, und dann in die Ontologie geladen. Sollte das Erstellen einzelner Attribute fehlschlagen, wird dies in den Logs vermerkt und sollte manuell überprüft werden."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T11:36:40.259240Z",
     "start_time": "2024-08-06T11:36:40.240112Z"
    }
   },
   "source": [
    "def intiiere_Ontologie():\n",
    "    logging.info(\"Initializing ontology...\")\n",
    "    onto = get_ontology(f\"http://test.org/{resultname}.owl\")\n",
    "    with onto:\n",
    "        # Define classes\n",
    "        class Asset(Thing):\n",
    "            pass\n",
    "\n",
    "        class Vulnerability(Thing):\n",
    "            pass\n",
    "\n",
    "        class Threat_example(Thing):\n",
    "            pass\n",
    "\n",
    "        class Control(Thing):\n",
    "            pass\n",
    "        \n",
    "        class Attribute(Thing): \n",
    "            pass\n",
    "        \n",
    "        class InformationSource(Thing):\n",
    "            pass\n",
    "        # Define control level subclasses\n",
    "        class LowLevelControl(Control):\n",
    "            pass\n",
    "\n",
    "        class MediumLevelControl(Control):\n",
    "            pass\n",
    "\n",
    "        class HighLevelControl(Control):\n",
    "            pass\n",
    "        \n",
    "        # define \n",
    "\n",
    "            \n",
    "        class ExplicitVulnerability(Vulnerability):\n",
    "            pass\n",
    "        \n",
    "        class GeneralClassAxiomenericVulnerability(Vulnerability):\n",
    "            pass\n",
    "        \n",
    "        class ControlType(Attribute): \n",
    "            pass\n",
    "\n",
    "        class SecurityAttribute(Attribute): \n",
    "            pass\n",
    "\n",
    "        class ThreatOrigin(Attribute): \n",
    "            pass\n",
    "\n",
    "        class ThreatSource(Attribute): \n",
    "            pass\n",
    "        \n",
    "\n",
    "        # Define object properties\n",
    "        class implementedBy(Control >> Asset):\n",
    "            pass\n",
    "\n",
    "        class hasInformationSource(Thing >> InformationSource):\n",
    "            pass\n",
    "            \n",
    "        class vulnerableTo(Asset >> Vulnerability):\n",
    "            pass\n",
    "\n",
    "        class exploitedBy_exapmle(Vulnerability >> Threat_example):\n",
    "            pass\n",
    "\n",
    "        class mitigatedBy(Vulnerability >> Control):\n",
    "            pass\n",
    "        \n",
    "        class mitigates(Control >> Vulnerability):\n",
    "            pass\n",
    "\n",
    "        class hasOrigin(Threat_example >> ThreatOrigin): \n",
    "            pass\n",
    "        \n",
    "        class hasSource(Threat_example >> ThreatSource): \n",
    "            pass\n",
    "\n",
    "        class affects(Control >> SecurityAttribute): \n",
    "            pass  \n",
    "\n",
    "        class isresponsible(AnnotationProperty):\n",
    "            pass \n",
    "\n",
    "        class description(AnnotationProperty):\n",
    "            pass \n",
    "    logging.info(\"Ontology initialized successfully.\")\n",
    "    return onto\n",
    "def create_baustein (link, onto, failed=False):\n",
    "    #logging.info(f\"Processing baustein from link: {link}\")\n",
    "    generated = generate(link, failed)\n",
    "    try:\n",
    "        json_data = llm_output_to_json(generated)\n",
    "        logging.info(f\"Successfully generated JSON data from link: {link}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to generate JSON data from link: {link}. Error: {e}\")\n",
    "        return onto\n",
    "    print(\"generating finished\")\n",
    "    json_data = populate_json_with_excel_data(json_data, read_excel_sheet(json_data[\"handle\"]))\n",
    "    GefahrenQuelle = [{'handle': 'G 0.1', 'text': 'Feuer'}, {'handle': 'G 0.2', 'text': 'Ungünstige klimatische Bedingungen'}, {'handle': 'G 0.3', 'text': 'Wasser'}, {'handle': 'G 0.4', 'text': 'Verschmutzung, Staub, Korrosion'}, {'handle': 'G 0.5', 'text': 'Naturkatastrophen'}, {'handle': 'G 0.6', 'text': 'Katastrophen im Umfeld'}, {'handle': 'G 0.7', 'text': 'Großereignisse im Umfeld'}, {'handle': 'G 0.8', 'text': 'Ausfall oder Störung der Stromversorgung'}, {'handle': 'G 0.9', 'text': 'Ausfall oder Störung von Kommunikationsnetzen'}, {'handle': 'G 0.10', 'text': 'Ausfall oder Störung von Versorgungsnetzen'}, {'handle': 'G 0.11', 'text': 'Ausfall oder Störung von Dienstleistungsunternehmen'}, {'handle': 'G 0.12', 'text': 'Elektromagnetische Störstrahlung'}, {'handle': 'G 0.13', 'text': 'Abfangen kompromittierender Strahlung'}, {'handle': 'G 0.14', 'text': 'Ausspähen von Informationen (Spionage)'}, {'handle': 'G 0.15', 'text': 'Abhören'}, {'handle': 'G 0.16', 'text': 'Diebstahl von Geräten, Datenträgern oder Dokumenten'}, {'handle': 'G 0.17', 'text': 'Verlust von Geräten, Datenträgern oder Dokumenten'}, {'handle': 'G 0.18', 'text': 'Fehlplanung oder fehlende Anpassung'}, {'handle': 'G 0.19', 'text': 'Offenlegung schützenswerter Informationen'}, {'handle': 'G 0.20', 'text': 'Informationen oder Produkte aus unzuverlässiger Quelle'}, {'handle': 'G 0.21', 'text': 'Manipulation von Hard- oder Software'}, {'handle': 'G 0.22', 'text': 'Manipulation von Informationen'}, {'handle': 'G 0.23', 'text': 'Unbefugtes Eindringen in IT-Systeme'}, {'handle': 'G 0.24', 'text': 'Zerstörung von Geräten oder Datenträgern'}, {'handle': 'G 0.25', 'text': 'Ausfall von Geräten oder Systemen'}, {'handle': 'G 0.26', 'text': 'Fehlfunktion von Geräten oder Systemen'}, {'handle': 'G 0.27', 'text': 'Ressourcenmangel'}, {'handle': 'G 0.28', 'text': 'Software-Schwachstellen oder -Fehler'}, {'handle': 'G 0.29', 'text': 'Verstoß gegen Gesetze oder Regelungen'}, {'handle': 'G 0.30', 'text': 'Unberechtigte Nutzung oder Administration von Geräten und Systemen'}, {'handle': 'G 0.31', 'text': 'Fehlerhafte Nutzung oder Administration von Geräten und Systemen'}, {'handle': 'G 0.32', 'text': 'Missbrauch von Berechtigungen'}, {'handle': 'G 0.33', 'text': 'Personalausfall'}, {'handle': 'G 0.34', 'text': 'Anschlag'}, {'handle': 'G 0.35', 'text': 'Nötigung, Erpressung oder Korruption'}, {'handle': 'G 0.36', 'text': 'Identitätsdiebstahl'}, {'handle': 'G 0.37', 'text': 'Abstreiten von Handlungen'}, {'handle': 'G 0.38', 'text': 'Missbrauch personenbezogener Daten'}, {'handle': 'G 0.39', 'text': 'Schadprogramme'}, {'handle': 'G 0.40', 'text': 'Verhinderung von Diensten (Denial of Service)'}, {'handle': 'G 0.41', 'text': 'Sabotage'}, {'handle': 'G 0.42', 'text': 'Social Engineering'}, {'handle': 'G 0.43', 'text': 'Einspielen von Nachrichten'}, {'handle': 'G 0.44', 'text': 'Unbefugtes Eindringen in Räumlichkeiten'}, {'handle': 'G 0.45', 'text': 'Datenverlust'}, {'handle': 'G 0.46', 'text': 'Integritätsverlust schützenswerter Informationen'}, {'handle': 'G 0.47', 'text': 'Schädliche Seiteneffekte IT-gestützter Angriffe'}]\n",
    "    print(\"processing \" + json_data[\"name\"])\n",
    "    with (onto): \n",
    "        accidental = onto.ThreatSource(\"Accidental\")\n",
    "        malicious = onto.ThreatSource(\"malicious\")\n",
    "        human = onto.ThreatOrigin(\"human\")\n",
    "        natural = onto.ThreatOrigin(\"natural\")\n",
    "        gefahren = [onto.Threat_example(gefahr[\"text\"].replace('\"',\"'\")) for gefahr in GefahrenQuelle]\n",
    "        confidentiality = onto.SecurityAttribute(\"confidentiality\")\n",
    "        integrity = onto.SecurityAttribute(\"integrity\")\n",
    "        availability = onto.SecurityAttribute(\"availability\")\n",
    "        # Asset specific\n",
    "        asset = onto.Asset(json_data[\"name\"].replace('\"',\"'\"))\n",
    "        asset.hasInformationSource =  [onto.InformationSource(json_data[\"Informationsource\"])]\n",
    "        if not failed: asset.description = json_data[\"text\"].replace('\"',\"'\")\n",
    "        vulnerabilities = []\n",
    "        for vuln_data in json_data[\"vulnerableTo\"]:\n",
    "            vulnerability = onto.Vulnerability(vuln_data[\"name\"].replace('\"',\"'\"))\n",
    "            if not failed:vulnerability.description = vuln_data[\"text\"].replace('\"',\"'\")\n",
    "            vulnerability.hasInformationSource.append(onto.InformationSource(vuln_data[\"Informationsource\"]))\n",
    "            threats = []\n",
    "            if len(vuln_data[\"exploitedBy_examples\"]) > 0:\n",
    "                for threat_json in vuln_data[\"exploitedBy_examples\"]:\n",
    "                    threat =  onto.Threat_example(threat_json[\"name\"].replace('\"',\"'\"))\n",
    "                    if not failed: threat.description = threat_json[\"text\"].replace('\"',\"'\")\n",
    "                    threat.hasInformationSource =  [onto.InformationSource(vuln_data[\"Informationsource\"])]\n",
    "                    try:\n",
    "                        for origin in threat_json[\"hasOrigin\"]:\n",
    "                            if origin in [\"human\", \"natural\"]:\n",
    "                                threat.hasOrigin.append({\"human\": human, \"natural\": natural}[origin])\n",
    "                    except Exception as e: \n",
    "                        threat.hasOrigin = []\n",
    "                        logging.warning(f\"Failed to add origin to threat: {e} on {threat_json['name']}\")\n",
    "                    try:\n",
    "                        for source in threat_json[\"hasSource\"]:\n",
    "                            if source in [\"accidental\", \"malicious\"]:\n",
    "                                threat.hasSource.append({\"accidental\": accidental, \"deliberate\": malicious}[source])\n",
    "                    except Exception as e:\n",
    "                        logging.warning(f\"Failed to add source to threat: {e} on {threat_json['name']}\")\n",
    "                        threat.hasSource = []\n",
    "                    threats.append(threat)    \n",
    "                vulnerability.exploitedBy_exapmle = threats\n",
    "        asset.vulnerableTo = vulnerabilities\n",
    "\n",
    "        for control_data in json_data[\"Controls\"]:\n",
    "            level = control_data[\"level\"].lower()  # Convert to lowercase for matching\n",
    "            control_class = {\"low\":  onto.LowLevelControl, \"medium\":  onto.MediumLevelControl, \"high\":  onto.HighLevelControl}[level]\n",
    "            control = control_class(str(control_data[\"handle\"]+  \" \"+ control_data[\"name\"].replace('\"',\"'\")))\n",
    "            control.hasInformationSource =  [onto.InformationSource(control_data[\"Informationsource\"])]\n",
    "            for affect in control_data[\"affects\"]:\n",
    "                try: \n",
    "                    for letter in affect:\n",
    "                        control.affects.append({\"A\": availability, \"C\": confidentiality, \"I\": integrity }[letter])\n",
    "                    control.mitigates = [gefahren[int(gefahrtext.split(\".\")[1])-1] for gefahrtext in control_data[\"mitigates\"]]\n",
    "                except Exception as e: \n",
    "                    print(f\"failed to add affect to control: {e} of {control_data['name']}\")\n",
    "                    logging.warning(f\"failed to add affect to control: {e} of {control_data['name']}\")\n",
    "            try:\n",
    "                if not failed: \n",
    "                    content = str(control_data[\"text\"])\n",
    "                    content = content.replace('\"',\"'\")\n",
    "                    control.description = content\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to encode description to control: {e} on {control_data['name']}\")\n",
    "                control.description = \"\"\n",
    "            try:\n",
    "                control.isresponsible = control_data[\"isresponsible\"]\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to add responsible entity to control: {e} on {control_data['name']}\")\n",
    "                control.isresponsible = []\n",
    "            control.implementedBy.append(asset)\n",
    "    return onto\n",
    "\n",
    "def ontologie_speichern(onto):\n",
    "    with onto:\n",
    "        onto.save(file=f\"{resultname}.owl\", format=\"rdfxml\")\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "In diesem Block werden alle vorherigen Schritte aufgerufen. Für jeden Link wird versucht, ein vollständiges Dictionary zu erstellen. Sollte dies fehlschlagen, wird in einer zweiten Iteration für alle fehlgeschlagenen Links neue JSONs ohne Beschreibungen erzeugt. Dies liegt daran, dass die Beschreibungen aufgrund der Einschränkungen von Gemini häufig zu Fehlern führen. Das finale Ergebnis wird anschließend durch die Funktion **ontologie_speichern** gespeichert."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#create seperate trace and a log files\n",
    "logging.basicConfig(filename='ontology_creation2.log', level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "failed = []\n",
    "onto = intiiere_Ontologie()\n",
    "\n",
    "for link in links_array:\n",
    "    try:\n",
    "        onto = create_baustein(link,onto) \n",
    "    except Exception as e:\n",
    "        failed.append(link)\n",
    "logging.info(f\"Failed links: {len(failed)}\")\n",
    "for i in failed:\n",
    "    try: \n",
    "        onto = create_baustein(i, onto, True)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Retry failed for link: {i} - Error: {e}\")\n",
    "ontologie_speichern(onto)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Funktion hilft dabei, Formatierungsfehler in der resultierenden .owl-Datei in Protege vorzubeugen, indem sie Anführungszeichen (”) in Textblöcken ersetzt.\n",
    "Dennoch sollte die Datei vor Verwendung in einer Ontologie Software wie Protege geöffnet werden, da dabei noch Fehler auftreten können die nicht durch diese Vorbehandlung verhindert werden können. Um diese zu beheben: Überprüfen Sie die genannten Stellen in der OWL Datei in einem Texteditor, oft müssen hier Sonderzeichen oder Kodierungsfehler ausgebessert werden. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T14:17:26.454291Z",
     "start_time": "2024-08-06T14:17:26.433356Z"
    }
   },
   "source": [
    "def replace_quotes_in_file(file_path):\n",
    "    \"\"\"\n",
    "    Replaces nested double quotes within rdf:about attributes with single quotes\n",
    "    in an RDF/XML file, modifying the file in place.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the RDF/XML file to be modified.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for line in fileinput.input(file_path, inplace=True):\n",
    "            # Step 1: Handle nested double quotes\n",
    "            line = re.sub(r'(rdf:about=\"#)([^\"]*)(\")([^\"]*)(\")', r'\\1\\2&quot;\\4&quot;', line)\n",
    "\n",
    "            # Step 2: Replace &quot; entities with '\n",
    "            line = line.replace(\"&quot;\", \"'\")\n",
    "            line = line.replace(\"%20\", \"_\")\n",
    "            \n",
    "            print(line, end=\"\")  # Print the modified line (fileinput.input will write it back)\n",
    "\n",
    "        print(f\"Quotes replaced successfully in file: {file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = f\"{resultname}.owl\"  # Replace with your file's path\n",
    "replace_quotes_in_file(file_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quotes replaced successfully in file: cybersecurity_complete_v14.owl\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Abschließend müssen zur Sicherstellung der Qualität noch folgende Schritte erfolgen:\n",
    "1. Durchgehen der .log-Datei: Am häufigsten treten Warnungen auf, da optionale Informationen nicht gefunden werden. Diese können ignoriert werden.\n",
    "2. Fehlerbehandlung bei maximaler Outputlänge: Übersteigen Beschreibungen von Gefahren oder Kontrollen die maximale Outputlänge des LLMs, wird der Fehler “Error: Expecting ‘,’ delimiter: …” zurückgegeben. Um zu verhindern, dass dadurch ganze Bausteine nicht im Graphen abgebildet sind, werden im zweiten Schritt nur die Objekte ohne Beschreibungen erstellt. Falls gewünscht, müssen die Beschreibungen der entsprechenden Bausteine dann manuell in einer Bearbeitungssoftware wie Protege nachträglich hinzugefügt werden.\n",
    "3. Umgang mit sicherheitsbedenklichen Bausteinen: Dasselbe gilt auch für Bausteine, die aufgrund von Sicherheitsbedenken durch die API zurückgehalten werden.\n",
    "4. Manueller Vergleich zur Gewährleistung der Korrektheit: Um die vollständige Korrektheit des Wissensgraphen gewährleisten zu können, ist ein manueller Vergleich des Graphen mit dem Grundschutzkompendium notwendig."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
